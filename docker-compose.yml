services:
  # 1. Frontend: The "Cockpit"
  re-web2:
    build: ./web
    container_name: re-web2
    ports:
      - "3000:3000"
    environment:
      # INTERNAL_API_URL allows the Next.js server to proxy requests to the backend container
      - INTERNAL_API_URL=http://re-api2:8000
      # NEXT_PUBLIC_API_URL can be left blank to use the proxy (best for remote access via IP).
      # Set this only if you want to bypass the proxy and talk to the API directly.
      - NEXT_PUBLIC_API_URL=http://localhost:8005

    depends_on:
      re-api2:
        condition: service_healthy
    networks:
      - re-net

  # 2. RAG Backend: The "Brain" (FastAPI + RAG Logic)
  re-api2:
    build: ./backend
    container_name: re-api2
    ports:
      - "8005:8000" # Changed host port to 8005
    volumes:
      - ./backend:/app
      - ./data:/data # For raw data ingestion
      - ./data/projects:/data/projects # Shared Projects
      - ./data/jobs:/data/jobs # Shared Job Queue
      - ./ghidra_scripts:/ghidra_scripts # Access to scripts to parse/update
      - ghidra-dist:/ghidra # Shared Ghidra installation
    environment:
      - CHROMA_HOST=re-memory2
      - CHROMA_PORT=8000
      - OLLAMA_HOST=http://re-ai2:11434
      - GHIDRA_HOST=re-ghidra2
    depends_on:
      re-memory2:
        condition: service_healthy
      re-ai2:
        condition: service_healthy
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:8000/health" ]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - re-net

  # 3. Ghidra: The "Analysis Engine"
  re-ghidra2:
    build: ./docker/ghidra # Custom build with X11/VNC
    container_name: re-ghidra2
    ports:
      - "5900:5900" # VNC
      - "6080:6080" # noVNC (Web Access)
    environment:
      - VNC_PASSWORD=ghidra
    volumes:
      - ./data/binaries:/ghidra/binaries
      - ./data/projects:/ghidra/projects
      - ./data/jobs:/ghidra/jobs
      - ./ghidra_scripts:/ghidra/scripts
      - ghidra-dist:/ghidra # Populate this volume

    networks:
      - re-net

  # 4. AI Core: Ollama
  re-ai2:
    image: ollama/ollama:latest
    container_name: re-ai2
    ports:
      - "11434:11434"
    volumes:
      - ollama-data:/root/.ollama
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [ gpu ]
    healthcheck:
      test: [ "CMD", "ollama", "list" ]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - re-net

  # 5. Connective Memory: ChromaDB
  re-memory2:
    image: chromadb/chroma:0.5.0
    container_name: re-memory2
    ports:
      - "8001:8000"
    volumes:
      - chroma-data-v2:/chroma/chroma
    environment:
      - ANONYMIZED_TELEMETRY=False
      - CHROMA_SERVER_HTTP_PORT=8000
    healthcheck:
      test: [ "CMD", "/bin/bash", "-c", "echo > /dev/tcp/127.0.0.1/8000" ]
      interval: 10s
      timeout: 5s
      retries: 10
      start_period: 30s
    networks:
      - re-net

networks:
  re-net:
    driver: bridge

volumes:
  ollama-data:
  chroma-data-v2:
  ghidra-dist:
